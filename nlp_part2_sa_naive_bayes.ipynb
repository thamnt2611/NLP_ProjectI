{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Giải quyết Sentiment Analysis dùng Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tải dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tải dữ liệu rồi cho dữ liệu vào trong pandas.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>xe_đẩy bán cơm_chiên nằm ngay đầu đường vào kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>món ăn lạ mà ngon . quán mới ra 3 món tomocorn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ghé quán_ăn mà đông quá_trời . tuy phục_vụ hơi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>gía cả bình_dân , chất_lượng tốt . món ăn khá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mình đã đến lacquer ăn trưa hò_hẹn với tụi bạn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0</td>\n",
       "      <td>chờ vừa lâu mà đồ_ăn vừa dở , chẳng có gì gọi_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0</td>\n",
       "      <td>k thích cách mấy nhân_viên phục_vụ - thiếu chu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0</td>\n",
       "      <td>sushi bình_thường , giá_cả lại không hợp_lý .\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0</td>\n",
       "      <td>1 năm ăn lại , chắc tại tiệm đông khách nên kĩ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>nhân_viên rất nhiệt_tình , kem không ngon lắm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                            comment\n",
       "0            1  xe_đẩy bán cơm_chiên nằm ngay đầu đường vào kh...\n",
       "1            1  món ăn lạ mà ngon . quán mới ra 3 món tomocorn...\n",
       "2            1  ghé quán_ăn mà đông quá_trời . tuy phục_vụ hơi...\n",
       "3            1  gía cả bình_dân , chất_lượng tốt . món ăn khá ...\n",
       "4            1  mình đã đến lacquer ăn trưa hò_hẹn với tụi bạn...\n",
       "..         ...                                                ...\n",
       "367          0  chờ vừa lâu mà đồ_ăn vừa dở , chẳng có gì gọi_...\n",
       "368          0  k thích cách mấy nhân_viên phục_vụ - thiếu chu...\n",
       "369          0  sushi bình_thường , giá_cả lại không hợp_lý .\\...\n",
       "370          0  1 năm ăn lại , chắc tại tiệm đông khách nên kĩ...\n",
       "371          0  nhân_viên rất nhiệt_tình , kem không ngon lắm ...\n",
       "\n",
       "[372 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import dirname\n",
    "def load_data(dir):\n",
    "    cmt={}\n",
    "    cmt['sentiment'] = 0 if (dir=='D:/dataset/sav/data_train/train/practice_neg') else 1\n",
    "    cmt['comment'] = []\n",
    "    for filename in listdir(dir):\n",
    "        file = open(\"{0}/{1}\".format(dir, filename), 'r', encoding='utf-8')\n",
    "        text = file.read().lower()\n",
    "        cmt['comment'].append(text)\n",
    "        file.close()\n",
    "    return cmt\n",
    "cmt_pos = load_data(\"D:/dataset/sav/data_train/train/practice_pos\")\n",
    "cmt_neg = load_data(\"D:/dataset/sav/data_train/train/practice_neg\")\n",
    "\n",
    "frame = pd.DataFrame(cmt_pos, columns=['sentiment', 'comment'])\n",
    "frame_2 = pd.DataFrame(cmt_neg, columns=['sentiment', 'comment'])\n",
    "frame = frame.append(frame_2, ignore_index = True)\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phân chia dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chia dữ liệu thành 2 tập train (X, y) và test (X_test, y_test)\n",
    "\n",
    "Tập train (X, y) sau này sẽ dùng cho cross-validation k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3506)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(frame, test_size=0.1)\n",
    "X = df_train['comment'].values\n",
    "y = df_train['sentiment'].values\n",
    "X_test = df_test['comment'].values\n",
    "y_test = df_test['sentiment'].values\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cảm_giác khj bước vào quán dc cả nhân_viên đến quản_lí đều hô chào bằng câu tiếng hàn rất thich thú\\ncảm_giác như mình là trung_điểm của quán hjjj\\nđồ_ăn ngon , vị lạ nhất_là món \" gà sôt vị cay \" : cay ơi_là cay , ngon ơi_là ngon\\ncòn được tặng thêm những chú gà bông xinh và siêu kute luôn nữa chứ hjjj\\ncác bạn thử 1 lần đến quán nha\\nxem có như lời mình nói kô nhé ! !\\nđảm_bảo đi 1 lần lại muốn đi lần nữa như mình ý 😘 😘 😘 😘 😘\\n'\n",
      " 'không_gian đẹp , khá ấm_cúng . giá hợp_lý nếu sử_dụng các gói student hay_là gói 40h . giá lẻ hơi đắt 😅 😅\\n'\n",
      " 'nay thèm sushi quá tình_cờ thấy quán này nên gọi ngay . vì có một_mình mình ăn nên chỉ gọi một phần mà quán cũng giao luôn . ship rẻ lắm . mà tận gần 22h . nhiệt_tình lắm . mình mua sushi chiên . vừa chiên xù nóng_hổi giòn_rụm nắp hộp còn đọng hơi_nước luôn . ngon lắm . sốt béo cay_cay ăn giờ còn ghiền . chắc mai sẽ kêu ăn tiếp . giá 29k mà 8 khoanh luôn , ăn no căng mà không ngán . mấy phần khác cũng 19-29-39k thôi à .\\nđiện_thoại chụp hình không đẹp lắm . chứ quán decor đẹp_mắt lắm .\\ncó bán đem đi_ở 29 đường 12 gần hồ bơi làng hoa nữa\\n'\n",
      " 'thứ 6 nào ta cùng quẩy 💣 💣 💣\\nvuvuzela beer club chung hệ_thống gogi_house , daruma , kichi kichi nên giá cũng chưa 10% vat . thanh_toán trước 20g hằng ngày đc giảm 30% thức_ăn . tính ra đc giảm 20% . cũng zui ! 😊 😊 😊\\nngồi thư_giãn cũng ok . thức_ăn cũng ổn . có mấy món nguyên_liệu bên ngoài hok bik chỗ nào bán nên vô đây ăn . cơ_mà gọi mấy món đó cũng ko có hàng 😂 😂 😂\\ncháo bồ_câu hình chụp nguyên con bồ_câu mà tìm hoài chỉ thấy phao_câu không thấy đầu bồ_câu . hỏi e nv e chạy hỏi nhà_bếp đc trả_lời là 1 phần cháo đc tính_toán 1 lượng thịt cố_định theo gram chứ không phải nguyên con chị ơi . 😅 😅 😅\\nps : lần sau sẽ rủ trên 4 đứa đi quẩy để đc tặng 10 ly biaaaaaaaaaaaaaa mí đc 🍺 🍺 🍺 🍺 🍺 🍺 🍺 🍺 🍺 🍺\\n'\n",
      " 'mình có dịp đi ăn thử chỗ này với bạn_bè . nhóm mình đi 8 người nên thử được khá nhiều món . nhìn_chung thì khẩu_phần món ăn_ở đây tương_đối nhiều nên đi đông người thì sẽ thử được nhiều hơn . vì là quán_ăn chuyên về gà nên ăn nhiều cũng mau ngán lắm . phục_vụ thì nhiều lúc đông khách quá nên cũng hơi lơ_là xíu . khuyên mọi người là nên đặt chỗ sớm vì sau 7h tối thì đôi_khi đặt chỗ rồi đến vẫn phải chờ vì quá đông . giá đồ_ăn dao_động khoảng 150-250 , đi đông chia ra sẽ tiện hơn . khôg gian hơi nhỏ nên đi đông cũng hơi bất_tiện xíu trong khâu xếp bàn .\\n']\n",
      "[1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X[0:5])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Làm sạch dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loại bỏ các ký tự đặc biệt & chữ số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cảm_giác khj bước vào quán dc cả nhân_viên đến quản_lí đều hô chào bằng câu tiếng hàn rất thich thúcảm_giác như mình là trung_điểm của quán hjjjđồ_ăn ngon  vị lạ nhất_là món  gà sôt vị cay   cay ơi_là cay  ngon ơi_là ngoncòn được tặng thêm những chú gà bông xinh và siêu kute luôn nữa chứ hjjjcác bạn thử  lần đến quán nhaxem có như lời mình nói kô nhé ! !đảm_bảo đi  lần lại muốn đi lần nữa như mình ý 😘 😘 😘 😘 😘',\n",
       " 'không_gian đẹp  khá ấm_cúng  giá hợp_lý nếu sử_dụng các gói student hay_là gói h  giá lẻ hơi đắt 😅 😅',\n",
       " 'nay thèm sushi quá tình_cờ thấy quán này nên gọi ngay  vì có một_mình mình ăn nên chỉ gọi một phần mà quán cũng giao luôn  ship rẻ lắm  mà tận gần h  nhiệt_tình lắm  mình mua sushi chiên  vừa chiên xù nóng_hổi giòn_rụm nắp hộp còn đọng hơi_nước luôn  ngon lắm  sốt béo cay_cay ăn giờ còn ghiền  chắc mai sẽ kêu ăn tiếp  giá k mà  khoanh luôn  ăn no căng mà không ngán  mấy phần khác cũng k thôi à điện_thoại chụp hình không đẹp lắm  chứ quán decor đẹp_mắt lắm có bán đem đi_ở  đường  gần hồ bơi làng hoa nữa',\n",
       " 'thứ  nào ta cùng quẩy 💣 💣 💣vuvuzela beer club chung hệ_thống gogi_house  daruma  kichi kichi nên giá cũng chưa % vat  thanh_toán trước g hằng ngày đc giảm % thức_ăn  tính ra đc giảm %  cũng zui ! 😊 😊 😊ngồi thư_giãn cũng ok  thức_ăn cũng ổn  có mấy món nguyên_liệu bên ngoài hok bik chỗ nào bán nên vô đây ăn  cơ_mà gọi mấy món đó cũng ko có hàng 😂 😂 😂cháo bồ_câu hình chụp nguyên con bồ_câu mà tìm hoài chỉ thấy phao_câu không thấy đầu bồ_câu  hỏi e nv e chạy hỏi nhà_bếp đc trả_lời là  phần cháo đc tính_toán  lượng thịt cố_định theo gram chứ không phải nguyên con chị ơi  😅 😅 😅ps  lần sau sẽ rủ trên  đứa đi quẩy để đc tặng  ly biaaaaaaaaaaaaaa mí đc 🍺 🍺 🍺 🍺 🍺 🍺 🍺 🍺 🍺 🍺',\n",
       " 'mình có dịp đi ăn thử chỗ này với bạn_bè  nhóm mình đi  người nên thử được khá nhiều món  nhìn_chung thì khẩu_phần món ăn_ở đây tương_đối nhiều nên đi đông người thì sẽ thử được nhiều hơn  vì là quán_ăn chuyên về gà nên ăn nhiều cũng mau ngán lắm  phục_vụ thì nhiều lúc đông khách quá nên cũng hơi lơ_là xíu  khuyên mọi người là nên đặt chỗ sớm vì sau h tối thì đôi_khi đặt chỗ rồi đến vẫn phải chờ vì quá đông  giá đồ_ăn dao_động khoảng   đi đông chia ra sẽ tiện hơn  khôg gian hơi nhỏ nên đi đông cũng hơi bất_tiện xíu trong khâu xếp bàn ']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def cleandata(cmts):\n",
    "    data = []\n",
    "    for i in cmts:\n",
    "        data.append(re.sub(r\"[-()\\\"#/@;:<>{}=~|.?,\\n0-9]\", \"\", i))\n",
    "    return data\n",
    "X = cleandata(X)\n",
    "X_test = cleandata(X_test)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tạo vector bag-of-word cho mỗi câu bình luận"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu các bag-of-word vector dưới dạng dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 3586)\n",
      "3586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform(X)\n",
    "bow_test = vectorizer.transform(X_test)\n",
    "print(bow.toarray().shape)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334, 3586)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow = pd.DataFrame(bow.toarray(), columns = vocab)\n",
    "df_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a_bảo', 'aaaaaaa', 'accoustics', 'acoustic', 'acousticlivemusic',\n",
       "       'after', 'again', 'ah', 'ai', 'ai_ngờ',\n",
       "       ...\n",
       "       'ốc_bươu', 'ống', 'ốp', 'ồn', 'ồn_ào', 'ổn', 'ổng', 'ổnđiểm', 'ớt',\n",
       "       'ủng_hộ'],\n",
       "      dtype='object', length=3586)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_bảo</th>\n",
       "      <th>aaaaaaa</th>\n",
       "      <th>accoustics</th>\n",
       "      <th>acoustic</th>\n",
       "      <th>acousticlivemusic</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>ah</th>\n",
       "      <th>ai</th>\n",
       "      <th>ai_ngờ</th>\n",
       "      <th>...</th>\n",
       "      <th>ốc_bươu</th>\n",
       "      <th>ống</th>\n",
       "      <th>ốp</th>\n",
       "      <th>ồn</th>\n",
       "      <th>ồn_ào</th>\n",
       "      <th>ổn</th>\n",
       "      <th>ổng</th>\n",
       "      <th>ổnđiểm</th>\n",
       "      <th>ớt</th>\n",
       "      <th>ủng_hộ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3586 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a_bảo  aaaaaaa  accoustics  acoustic  acousticlivemusic  after  again  ah  \\\n",
       "0      0        0           0         0                  0      0      0   0   \n",
       "1      0        0           0         0                  0      0      0   0   \n",
       "2      0        0           0         0                  0      0      0   0   \n",
       "3      0        0           0         0                  0      0      0   0   \n",
       "4      0        0           0         0                  0      0      0   0   \n",
       "\n",
       "   ai  ai_ngờ  ...  ốc_bươu  ống  ốp  ồn  ồn_ào  ổn  ổng  ổnđiểm  ớt  ủng_hộ  \n",
       "0   0       0  ...        0    0   0   0      0   0    0       0   0       0  \n",
       "1   0       0  ...        0    0   0   0      0   0    0       0   0       0  \n",
       "2   0       0  ...        0    0   0   0      0   0    0       0   0       0  \n",
       "3   0       0  ...        0    0   0   0      0   0    0       0   0       0  \n",
       "4   0       0  ...        0    0   0   0      0   0    0       0   0       0  \n",
       "\n",
       "[5 rows x 3586 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow_test = pd.DataFrame(bow_test.toarray(), columns = vocab)\n",
    "df_bow_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xây dựng & đánh giá chất lượng mô hình Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử nghiệm 2 phương pháp : Multinomial Naive Bayes vs Bernoulli Naive Bayes\n",
    "\n",
    "Và dùng k-fold cross validation để chọn phương pháp nào hiệu quả hơn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = MultinomialNB()\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df_bow_train.append(df_bow_test)\n",
    "y = np.array(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8415329768270944\n",
      "0.7994652406417113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(10, True, 1)\n",
    "m_scores = []\n",
    "b_scores = []\n",
    "for train_index, test_index in kfold.split(df_bow_train):\n",
    "    X_train, X_val, y_train, y_val = df_bow.iloc[train_index], df_bow.iloc[test_index], y[train_index], y[test_index]\n",
    "    nb.fit(X_train, y_train)\n",
    "    bnb.fit(X_train, y_train)\n",
    "    m_scores.append(nb.score(X_val, y_val))\n",
    "    b_scores.append(bnb.score(X_val, y_val))\n",
    "print(np.mean(m_scores))\n",
    "print(np.mean(b_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8823529411764706, 0.8529411764705882, 0.7941176470588235, 0.7647058823529411, 0.7878787878787878, 0.9090909090909091, 0.7272727272727273, 0.9393939393939394, 0.9393939393939394, 0.8181818181818182]\n",
      "[0.8823529411764706, 0.6764705882352942, 0.7352941176470589, 0.8823529411764706, 0.7272727272727273, 0.7878787878787878, 0.696969696969697, 0.8484848484848485, 0.9090909090909091, 0.8484848484848485]\n"
     ]
    }
   ],
   "source": [
    "print(m_scores)\n",
    "print(b_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể thấy Multinomial Naive Bayes cho chất lượng tốt hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting class of cmt0: multinomial 1; bernoulli 1\n",
      "Class of cmt0:1\n",
      "Predicting class of cmt1: multinomial 1; bernoulli 1\n",
      "Class of cmt1:0\n",
      "Predicting class of cmt2: multinomial 0; bernoulli 0\n",
      "Class of cmt2:0\n",
      "Predicting class of cmt3: multinomial 1; bernoulli 0\n",
      "Class of cmt3:1\n",
      "Predicting class of cmt4: multinomial 1; bernoulli 0\n",
      "Class of cmt4:1\n",
      "Predicting class of cmt5: multinomial 1; bernoulli 0\n",
      "Class of cmt5:1\n",
      "Predicting class of cmt6: multinomial 1; bernoulli 1\n",
      "Class of cmt6:1\n",
      "Predicting class of cmt7: multinomial 0; bernoulli 0\n",
      "Class of cmt7:0\n",
      "Predicting class of cmt8: multinomial 0; bernoulli 0\n",
      "Class of cmt8:1\n",
      "Predicting class of cmt9: multinomial 1; bernoulli 0\n",
      "Class of cmt9:1\n",
      "Predicting class of cmt10: multinomial 0; bernoulli 0\n",
      "Class of cmt10:0\n",
      "Predicting class of cmt11: multinomial 0; bernoulli 0\n",
      "Class of cmt11:0\n",
      "Predicting class of cmt12: multinomial 1; bernoulli 1\n",
      "Class of cmt12:1\n",
      "Predicting class of cmt13: multinomial 1; bernoulli 1\n",
      "Class of cmt13:1\n",
      "Predicting class of cmt14: multinomial 1; bernoulli 1\n",
      "Class of cmt14:1\n",
      "Predicting class of cmt15: multinomial 1; bernoulli 0\n",
      "Class of cmt15:1\n",
      "Predicting class of cmt16: multinomial 1; bernoulli 1\n",
      "Class of cmt16:1\n",
      "Predicting class of cmt17: multinomial 1; bernoulli 1\n",
      "Class of cmt17:1\n",
      "Predicting class of cmt18: multinomial 1; bernoulli 1\n",
      "Class of cmt18:1\n",
      "Predicting class of cmt19: multinomial 1; bernoulli 1\n",
      "Class of cmt19:1\n"
     ]
    }
   ],
   "source": [
    "y_mpredict = nb.predict(df_bow_test)\n",
    "y_bpredict = bnb.predict(df_bow_test)\n",
    "for i in range(20):\n",
    "    print('Predicting class of cmt{}: multinomial {}; bernoulli {}'.format(i, str(y_mpredict[i]), str(y_bpredict[i]))) \n",
    "    print('Class of cmt{}:{}'.format(i,  str(y_test[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "153.438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
